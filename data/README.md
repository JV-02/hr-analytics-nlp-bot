# Data Directory Documentation

This folder contains all datasets used in the HR Analytics + NLP + Chatbot project.  
The data is intentionally not tracked in full to ensure privacy, compliance, and efficient repository size management.

---

## Directory Structure

data/
│
├── raw/
│ ├── hr/
│ │ └── WA_Fn-UseC_-HR-Employee-Attrition.csv
│ └── resumes/
│ ├── Resume.csv
│ └── README.md # Dataset privacy + source documentation
│
└── processed/
├── hr_clean.csv
├── resumes_clean.csv
└── embeddings/

---

## Purpose of Each Folder

### `raw/`
Contains unmodified datasets in their original form.  
These files should not be edited manually.

- raw/hr → IBM HR Attrition dataset  
- raw/resumes → Public or synthetic resume datasets  

### `processed/`
Contains datasets generated after cleaning or feature engineering.

Examples:
- Encoded HR datasets  
- Cleaned resume text  
- Embedding vectors  
- Tokenized/lemmatized text data  

---

## Data Governance & Privacy Guidelines

- Do not upload real PII (Personally Identifiable Information) to this repository.
- Large datasets (>100MB) must be excluded via .gitignore.
- Only anonymized or synthetic datasets are allowed publicly.
- Raw data should be stored here, while processed files must go in data/processed/.
- Document any new dataset source or preprocessing change.

---

## Reproducibility Notes

Processed datasets can be regenerated by running:

- Preprocessing notebooks inside notebooks/
- Scripts located in src/data/

This ensures anyone can reproduce your results.

---

## Contributor Instructions

If adding new datasets:

1. Place raw files in data/raw/<correct_subfolder>/
2. Do not commit private or sensitive data
3. Update this README to include source and description
